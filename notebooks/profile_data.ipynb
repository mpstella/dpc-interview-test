{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sqlite3\n",
    "import hashlib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Program variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODATE = datetime.datetime(2022, 3, 20)\n",
    "ODATE_MINUS_1 = ODATE - datetime.timedelta(days=1)\n",
    "\n",
    "DBNAME = \"DPC_IQ.db\"\n",
    "\n",
    "DROP_INITIAL_DATABASE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(os.getcwd()) / \"../\" / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(file_path / DBNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(connection, query):\n",
    "\n",
    "    cur = connection.cursor()\n",
    "    cur.execute(query)\n",
    "\n",
    "def initialise_db(connection, drop_tables=False):\n",
    "    \n",
    "    if drop_tables:\n",
    "        for _t in [\"country_dim\"]:\n",
    "            execute_query(connection, f\"DROP TABLE IF EXISTS {_t}\")\n",
    "          \n",
    "    _dim_create = \"\"\"\n",
    "    create table if not exists country_dim (\n",
    "        country_id INTEGER,\n",
    "        key TEXT,\n",
    "        place_id TEXT,\n",
    "        country_code TEXT,\n",
    "        country_name TEXT,\n",
    "        subregion1_code TEXT,\n",
    "        subregion1_name TEXT,\n",
    "        subregion2_name TEXT,\n",
    "        effective_start_date DATE,\n",
    "        effective_end_date DATE,\n",
    "        hash_val TEXT,\n",
    "        current_indicator INTEGER\n",
    "    )    \n",
    "    \"\"\"\n",
    "    \n",
    "    execute_query(connection, _dim_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some pandas helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hash(df):\n",
    "    # better to drop any existing hash_val incase this is run multiple times.\n",
    "    df.drop(['__str','hash_val'], axis=1, errors='ignore', inplace=True)\n",
    "    df['__str'] = df.astype(str).values.sum(axis=1)\n",
    "    df['hash_val'] = df['__str'].apply(lambda x: hashlib.md5(str(x).encode('utf-8')).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_db(conn, drop_tables=DROP_INITIAL_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_dimension = pd.read_sql_query(\"select key, hash_val from country_dim where current_indicator='1'\", conn)\n",
    "\n",
    "customer_dimension.set_index('key', inplace=True)\n",
    "\n",
    "print(customer_dimension.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = file_path / \"reference.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=ref, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_hash(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicate 'key' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_keys_df = df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {duplicate_keys_df.shape[0]} records that are duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the duplicates (for debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_load_pre = df.join(customer_dimension, how='left', on=['key'], rsuffix='_existing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create insert\n",
    "customer_dim_insert = customer_load_pre[customer_load_pre['hash_val_existing'].isnull()]\n",
    "del customer_dim_insert['hash_val_existing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_matched = customer_load_pre[~customer_load_pre['hash_val_existing'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create update\n",
    "customer_matched = customer_load_pre[~customer_load_pre['hash_val_existing'].isnull()]\n",
    "customer_dim_upsert = customer_matched.query('hash_val != hash_val_existing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_dim_insert.to_sql('stg_country_dim_insert', conn, if_exists='replace')\n",
    "customer_dim_upsert.to_sql('stg_country_dim_upsert', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_query = f\"\"\"\n",
    "update country_dim\n",
    "   set effective_end_date = '{ODATE_MINUS_1}',\n",
    "       current_indicator = 0\n",
    " where current_indicator = 1\n",
    "   and exists (\n",
    "         select 1 \n",
    "           from stg_country_dim_upsert\n",
    "          where key = country_dim.key\n",
    "          );\n",
    "\"\"\"\n",
    "execute_query(conn, update_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = f\"\"\"\n",
    "insert into country_dim\n",
    "(country_id, key, place_id, country_code, country_name, subregion1_code, subregion1_name, subregion2_name, effective_start_date, effective_end_date, hash_val, current_indicator)\n",
    "select row_number() over () + id_tbl.min_id as country_id,\n",
    "       stg.key,\n",
    "       stg.place_id,\n",
    "       stg.country_code,\n",
    "       stg.country_name,\n",
    "       stg.subregion1_code,\n",
    "       stg.subregion1_name,\n",
    "       stg.subregion2_name,\n",
    "       '{ODATE}' as 'effective_start_date',\n",
    "       '9999-12-31 00:00:00' as 'effective_end_date',\n",
    "       stg.hash_val,\n",
    "       1 as current_indicator\n",
    "from (\n",
    "select key,\n",
    "       place_id,\n",
    "       country_code,\n",
    "       country_name,\n",
    "       subregion1_code,\n",
    "       subregion1_name,\n",
    "       subregion2_name,\n",
    "       hash_val\n",
    " from stg_country_dim_insert\n",
    "union\n",
    "select key,\n",
    "       place_id,\n",
    "       country_code,\n",
    "       country_name,\n",
    "       subregion1_code,\n",
    "       subregion1_name,\n",
    "       subregion2_name,\n",
    "       hash_val\n",
    "  from stg_country_dim_upsert\n",
    "     ) stg\n",
    "cross join (select coalesce(max(country_id),0) as min_id from country_dim) id_tbl\n",
    "\"\"\"\n",
    "\n",
    "execute_query(conn, insert_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
